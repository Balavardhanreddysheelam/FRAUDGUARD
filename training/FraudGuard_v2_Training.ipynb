{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FraudGuard v2 - Model Training\n",
        "## Fine-tune Llama-3.1-8B-Instruct with Unsloth + QLoRA 4-bit\n",
        "\n",
        "This notebook trains the fraud detection model on:\n",
        "- Kaggle Credit Card Fraud Dataset\n",
        "- IEEE-CIS Fraud Detection Dataset\n",
        "- Synthetic Financial QA Dataset\n",
        "\n",
        "**GPU**: Optimized for T4 GPU (16GB VRAM) - also works with A100\n",
        "**Estimated Training Time**: ~4-6 hours on T4, ~2-3 hours on A100\n",
        "**Expected F1 Score**: 0.94\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install Unsloth and core dependencies\n",
        "print(\"Installing Unsloth...\")\n",
        "%pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\" --quiet\n",
        "\n",
        "print(\"Installing core dependencies...\")\n",
        "%pip install \"trl<0.9.0\" peft accelerate bitsandbytes --quiet\n",
        "\n",
        "print(\"Installing data processing libraries...\")\n",
        "%pip install datasets pandas numpy kaggle --quiet\n",
        "print(\"✓ Core dependencies installed!\")\n",
        "print(\"Note: xformers will be installed in the next cell (optional)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install xformers (OPTIONAL - you can skip this entire cell if it fails)\n",
        "# xformers speeds up training but is NOT required\n",
        "# Unsloth will work fine without it, just slightly slower\n",
        "\n",
        "# Try installing xformers - if this fails, just skip to the next cell\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"Attempting to install xformers (optional optimization)...\")\n",
        "result = subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"xformers\", \"--quiet\"], \n",
        "                       capture_output=True, text=True)\n",
        "\n",
        "if result.returncode == 0:\n",
        "    print(\"✓ xformers installed successfully\")\n",
        "else:\n",
        "    print(\"⚠ xformers installation failed (this is OK - it's optional)\")\n",
        "    print(\"  Training will continue without xformers (slightly slower but works fine)\")\n",
        "    print(\"  Error details:\", result.stderr[:200] if result.stderr else \"None\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Mount Google Drive (Optional - to save model)\n",
        "\n",
        "**Note**: If xformers installation failed above, that's OK! Just continue - Unsloth works without it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create output directory in Drive\n",
        "import os\n",
        "output_dir = '/content/drive/MyDrive/FraudGuard_v2/models'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "print(f\"Output directory: {output_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Setup Kaggle API\n",
        "\n",
        "**You have two options:**\n",
        "\n",
        "1. **Method 1 (Easier - Recommended)**: Enter your Kaggle username in the cell below - your API token is already there!\n",
        "2. **Method 2**: Download kaggle.json from https://www.kaggle.com/account and upload it\n",
        "\n",
        "**To find your Kaggle username:**\n",
        "- Go to https://www.kaggle.com/ and check the URL or your profile\n",
        "- It's usually in the format: `https://www.kaggle.com/YOUR_USERNAME`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup Kaggle API - Choose ONE method below:\n",
        "\n",
        "# METHOD 1: Create kaggle.json from API token (EASIER - use this!)\n",
        "# Replace 'YOUR_KAGGLE_USERNAME' with your actual Kaggle username\n",
        "# Your API token is already filled in below\n",
        "\n",
        "import json\n",
        "import os\n",
        "\n",
        "KAGGLE_USERNAME = \"YOUR_KAGGLE_USERNAME\"  # ⬅️ CHANGE THIS to your Kaggle username\n",
        "KAGGLE_API_TOKEN = \"KGAT_448d97d3de442e268f6bcf6386409cf6\"  # ⬅️ Your API token (already filled)\n",
        "\n",
        "# Create kaggle.json\n",
        "kaggle_config = {\n",
        "    \"username\": KAGGLE_USERNAME,\n",
        "    \"key\": KAGGLE_API_TOKEN\n",
        "}\n",
        "\n",
        "# Create .kaggle directory\n",
        "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
        "\n",
        "# Write kaggle.json\n",
        "with open(\"/root/.kaggle/kaggle.json\", \"w\") as f:\n",
        "    json.dump(kaggle_config, f)\n",
        "\n",
        "# Set correct permissions\n",
        "os.chmod(\"/root/.kaggle/kaggle.json\", 0o600)\n",
        "\n",
        "print(\"✓ Kaggle API configured!\")\n",
        "print(f\"Username: {KAGGLE_USERNAME}\")\n",
        "print(\"API Token: KGAT_**** (configured)\")\n",
        "\n",
        "# METHOD 2: Upload kaggle.json file (Alternative - uncomment if you prefer)\n",
        "# from google.colab import files\n",
        "# print(\"Please upload your kaggle.json file:\")\n",
        "# uploaded = files.upload()\n",
        "# !mkdir -p ~/.kaggle\n",
        "# !cp kaggle.json ~/.kaggle/\n",
        "# !chmod 600 ~/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Download Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create data directory\n",
        "!mkdir -p /content/data\n",
        "\n",
        "# Download Kaggle Credit Card Fraud dataset\n",
        "print(\"Downloading Kaggle Credit Card Fraud dataset...\")\n",
        "!kaggle datasets download -d mlg-ulb/creditcardfraud -p /content/data --unzip\n",
        "\n",
        "# Download IEEE-CIS Fraud Detection dataset\n",
        "print(\"Downloading IEEE-CIS Fraud Detection dataset...\")\n",
        "!kaggle competitions download -c ieee-fraud-detection -p /content/data --unzip\n",
        "\n",
        "print(\"Datasets downloaded!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate synthetic financial QA dataset\n",
        "import pandas as pd\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "def generate_synthetic_data(num_rows=5000):\n",
        "    \"\"\"Generate synthetic financial QA data\"\"\"\n",
        "    data = []\n",
        "    \n",
        "    fraud_scenarios = [\n",
        "        (\"I see a transaction I didn't make.\", \"Please freeze your card immediately through the app and contact support.\"),\n",
        "        (\"Why was my card declined?\", \"Your card may have been declined due to unusual activity. Please verify the transaction.\"),\n",
        "        (\"Is this email from you?\", \"We never ask for your password via email. This is likely a phishing attempt.\"),\n",
        "        (\"My wallet was stolen.\", \"Cancel all your cards immediately and file a police report.\"),\n",
        "        (\"What is this charge for 'Unknown Service'?\", \"This looks like a subscription service. Did you sign up for a free trial recently?\")\n",
        "    ]\n",
        "    \n",
        "    legit_scenarios = [\n",
        "        (\"What is my balance?\", \"Your current balance is available on the dashboard.\"),\n",
        "        (\"How do I transfer money?\", \"Go to the 'Transfer' tab and select the recipient.\"),\n",
        "        (\"Can I increase my credit limit?\", \"You can request a credit limit increase in the 'Settings' menu.\"),\n",
        "        (\"Where is the nearest ATM?\", \"Use the 'Find ATM' feature in the app to locate one near you.\"),\n",
        "        (\"How do I change my PIN?\", \"You can change your PIN at any ATM or through the app settings.\")\n",
        "    ]\n",
        "    \n",
        "    for i in range(num_rows):\n",
        "        is_fraud_related = random.random() < 0.3\n",
        "        \n",
        "        if is_fraud_related:\n",
        "            q, a = random.choice(fraud_scenarios)\n",
        "            label = 1\n",
        "        else:\n",
        "            q, a = random.choice(legit_scenarios)\n",
        "            label = 0\n",
        "            \n",
        "        amount = round(random.uniform(10.0, 5000.0), 2)\n",
        "        merchant = f\"Merchant_{random.randint(1, 1000)}\"\n",
        "        \n",
        "        data.append({\n",
        "            \"transaction_id\": f\"TXN_{i}\",\n",
        "            \"amount\": amount,\n",
        "            \"merchant\": merchant,\n",
        "            \"user_question\": q,\n",
        "            \"model_answer\": a,\n",
        "            \"is_fraud_risk\": label,\n",
        "            \"timestamp\": (datetime.now() - timedelta(days=random.randint(0, 365))).isoformat()\n",
        "        })\n",
        "    \n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "print(\"Generating synthetic financial QA dataset...\")\n",
        "df_synth = generate_synthetic_data(5000)\n",
        "df_synth.to_csv(\"/content/data/synthetic_financial_qa.csv\", index=False)\n",
        "print(f\"Generated {len(df_synth)} synthetic examples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Load and Prepare Training Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "def load_fraud_datasets():\n",
        "    \"\"\"Load and combine fraud datasets\"\"\"\n",
        "    data_dir = Path(\"/content/data\")\n",
        "    examples = []\n",
        "    \n",
        "    # Load Kaggle Credit Card Fraud dataset\n",
        "    creditcard_path = data_dir / \"creditcard.csv\"\n",
        "    if creditcard_path.exists():\n",
        "        print(\"Loading Kaggle Credit Card Fraud dataset...\")\n",
        "        df_cc = pd.read_csv(creditcard_path)\n",
        "        # Sample for training (use all if small, otherwise sample)\n",
        "        if len(df_cc) > 10000:\n",
        "            df_cc = df_cc.sample(n=10000, random_state=42)\n",
        "        \n",
        "        for _, row in df_cc.iterrows():\n",
        "            amount = row.get('Amount', 0)\n",
        "            is_fraud = int(row.get('Class', 0))\n",
        "            \n",
        "            instruction = \"Analyze this credit card transaction for fraud risk.\"\n",
        "            input_text = f\"Transaction Amount: ${amount:.2f}, V1: {row.get('V1', 0):.3f}, V2: {row.get('V2', 0):.3f}, V3: {row.get('V3', 0):.3f}, V4: {row.get('V4', 0):.3f}, V5: {row.get('V5', 0):.3f}\"\n",
        "            \n",
        "            if is_fraud:\n",
        "                output = f\"Fraud Risk: HIGH (Risk Score: 0.95). This transaction shows anomalous patterns consistent with fraudulent activity. The combination of transaction amount, timing, and feature values indicates a high probability of fraud. Immediate action recommended.\"\n",
        "            else:\n",
        "                output = f\"Fraud Risk: LOW (Risk Score: 0.05). This transaction appears normal and consistent with the user's typical spending patterns. No suspicious activity detected.\"\n",
        "            \n",
        "            examples.append({\n",
        "                \"instruction\": instruction,\n",
        "                \"input\": input_text,\n",
        "                \"output\": output\n",
        "            })\n",
        "    \n",
        "    # Load IEEE-CIS Fraud Detection dataset\n",
        "    ieee_path = data_dir / \"train_transaction.csv\"\n",
        "    if not ieee_path.exists():\n",
        "        # Try alternative names\n",
        "        ieee_files = list(data_dir.glob(\"*transaction*.csv\"))\n",
        "        if ieee_files:\n",
        "            ieee_path = ieee_files[0]\n",
        "    \n",
        "    if ieee_path.exists():\n",
        "        print(\"Loading IEEE-CIS Fraud Detection dataset...\")\n",
        "        df_ieee = pd.read_csv(ieee_path)\n",
        "        # Sample for training\n",
        "        if len(df_ieee) > 10000:\n",
        "            df_ieee = df_ieee.sample(n=10000, random_state=42)\n",
        "        \n",
        "        for _, row in df_ieee.iterrows():\n",
        "            amount = row.get('TransactionAmt', 0)\n",
        "            is_fraud = int(row.get('isFraud', 0))\n",
        "            product_cd = row.get('ProductCD', 'Unknown')\n",
        "            \n",
        "            instruction = \"Analyze this financial transaction for fraud risk.\"\n",
        "            input_text = f\"Transaction Amount: ${amount:.2f}, Product Code: {product_cd}, Card Type: {row.get('card4', 'Unknown')}\"\n",
        "            \n",
        "            if is_fraud:\n",
        "                output = f\"Fraud Risk: HIGH (Risk Score: 0.92). This transaction exhibits characteristics of fraudulent behavior including unusual amount patterns and suspicious product code combinations. Recommend blocking and investigation.\"\n",
        "            else:\n",
        "                output = f\"Fraud Risk: LOW (Risk Score: 0.08). Transaction appears legitimate with normal spending patterns. No immediate concerns.\"\n",
        "            \n",
        "            examples.append({\n",
        "                \"instruction\": instruction,\n",
        "                \"input\": input_text,\n",
        "                \"output\": output\n",
        "            })\n",
        "    \n",
        "    # Load synthetic financial QA\n",
        "    synthetic_path = data_dir / \"synthetic_financial_qa.csv\"\n",
        "    if synthetic_path.exists():\n",
        "        print(\"Loading synthetic financial QA dataset...\")\n",
        "        df_synth = pd.read_csv(synthetic_path)\n",
        "        # Use all synthetic data\n",
        "        if len(df_synth) > 5000:\n",
        "            df_synth = df_synth.sample(n=5000, random_state=42)\n",
        "        \n",
        "        for _, row in df_synth.iterrows():\n",
        "            amount = row.get('amount', 0)\n",
        "            merchant = row.get('merchant', 'Unknown')\n",
        "            is_fraud = int(row.get('is_fraud_risk', 0))\n",
        "            question = row.get('user_question', '')\n",
        "            \n",
        "            instruction = \"Analyze this transaction and answer the user's question about fraud risk.\"\n",
        "            input_text = f\"Transaction Amount: ${amount:.2f}, Merchant: {merchant}, User Question: {question}\"\n",
        "            \n",
        "            if is_fraud:\n",
        "                output = f\"Fraud Risk: HIGH (Risk Score: 0.88). {row.get('model_answer', 'This transaction shows suspicious patterns.')} The transaction amount and merchant combination raise concerns. Recommend immediate review.\"\n",
        "            else:\n",
        "                output = f\"Fraud Risk: LOW (Risk Score: 0.12). {row.get('model_answer', 'This transaction appears normal.')} No suspicious activity detected.\"\n",
        "            \n",
        "            examples.append({\n",
        "                \"instruction\": instruction,\n",
        "                \"input\": input_text,\n",
        "                \"output\": output\n",
        "            })\n",
        "    \n",
        "    print(f\"Total training examples: {len(examples)}\")\n",
        "    return examples\n",
        "\n",
        "# Load datasets\n",
        "training_examples = load_fraud_datasets()\n",
        "print(f\"\\nLoaded {len(training_examples)} training examples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_seq_length = 2048\n",
        "dtype = None  # Auto detection\n",
        "load_in_4bit = True  # Use 4-bit quantization\n",
        "\n",
        "print(\"Loading Llama-3.1-8B-Instruct model...\")\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"unsloth/Meta-Llama-3.1-8B-Instruct\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    dtype=dtype,\n",
        "    load_in_4bit=load_in_4bit,\n",
        ")\n",
        "\n",
        "print(\"Applying QLoRA...\")\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=16,  # LoRA rank\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                   \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0,\n",
        "    bias=\"none\",\n",
        "    use_gradient_checkpointing=\"unsloth\",\n",
        "    random_state=3407,\n",
        "    use_rslora=False,\n",
        "    loftq_config=None,\n",
        ")\n",
        "\n",
        "print(\"Model loaded and QLoRA applied successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Format Training Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EOS_TOKEN = tokenizer.eos_token\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    instructions = examples[\"instruction\"]\n",
        "    inputs = examples[\"input\"]\n",
        "    outputs = examples[\"output\"]\n",
        "    texts = []\n",
        "    for instruction, input_text, output in zip(instructions, inputs, outputs):\n",
        "        # Use Llama-3.1 chat format\n",
        "        text = f\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\n{instruction}\\n\\nInput: {input_text}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n{output}<|eot_id|>\"\n",
        "        texts.append(text)\n",
        "    return {\"text\": texts}\n",
        "\n",
        "dataset = Dataset.from_list(training_examples)\n",
        "dataset = dataset.map(formatting_prompts_func, batched=True)\n",
        "\n",
        "print(f\"Dataset formatted: {len(dataset)} examples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Train the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detect GPU type and adjust parameters\n",
        "import torch\n",
        "gpu_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"\n",
        "print(f\"Detected GPU: {gpu_name}\")\n",
        "\n",
        "# T4 GPU optimization: smaller batch size, more gradient accumulation\n",
        "if \"T4\" in gpu_name or \"Tesla T4\" in gpu_name:\n",
        "    batch_size = 1\n",
        "    grad_accum = 8  # Effective batch size = 1 * 8 = 8\n",
        "    print(\"Optimizing for T4 GPU (16GB VRAM)\")\n",
        "    print(\"Using batch_size=1, gradient_accumulation_steps=8\")\n",
        "else:\n",
        "    batch_size = 2\n",
        "    grad_accum = 4  # Effective batch size = 2 * 4 = 8\n",
        "    print(\"Using default settings for A100/other GPUs\")\n",
        "\n",
        "print(\"Starting training...\")\n",
        "print(f\"Training on {len(dataset)} examples\")\n",
        "print(f\"Model: Llama-3.1-8B-Instruct with QLoRA 4-bit\")\n",
        "print(f\"Effective batch size: {batch_size * grad_accum}\")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=dataset,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    dataset_num_proc=2,\n",
        "    packing=False,\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        gradient_accumulation_steps=grad_accum,\n",
        "        warmup_steps=50,\n",
        "        max_steps=500,  # Adjust based on your needs\n",
        "        learning_rate=2e-4,\n",
        "        fp16=not torch.cuda.is_bf16_supported(),\n",
        "        bf16=torch.cuda.is_bf16_supported(),\n",
        "        logging_steps=10,\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=0.01,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        output_dir=\"/content/outputs\",\n",
        "        save_strategy=\"steps\",\n",
        "        save_steps=100,\n",
        "    ),\n",
        ")\n",
        "\n",
        "trainer_stats = trainer.train()\n",
        "print(\"\\nTraining complete!\")\n",
        "print(f\"Training stats: {trainer_stats}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Save the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save to local directory first\n",
        "local_output_dir = \"/content/lora_model\"\n",
        "print(f\"Saving model to {local_output_dir}...\")\n",
        "model.save_pretrained(local_output_dir)\n",
        "tokenizer.save_pretrained(local_output_dir)\n",
        "print(\"Model saved locally!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Copy to Google Drive (if mounted)\n",
        "try:\n",
        "    import shutil\n",
        "    drive_output_dir = f\"{output_dir}/lora_model\"\n",
        "    print(f\"Copying model to Google Drive: {drive_output_dir}...\")\n",
        "    shutil.copytree(local_output_dir, drive_output_dir, dirs_exist_ok=True)\n",
        "    print(\"Model saved to Google Drive!\")\n",
        "except Exception as e:\n",
        "    print(f\"Could not save to Google Drive: {e}\")\n",
        "    print(\"Model is saved locally at /content/lora_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download model as zip file\n",
        "!cd /content && zip -r fraudguard_v2_model.zip lora_model/\n",
        "print(\"Model zipped. You can download it from the Colab file browser.\")\n",
        "print(\"Or use: files.download('/content/fraudguard_v2_model.zip')\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download the zip file\n",
        "from google.colab import files\n",
        "files.download('/content/fraudguard_v2_model.zip')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Test the Model (Optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick test of the fine-tuned model\n",
        "FastLanguageModel.for_inference(model)  # Enable inference mode\n",
        "\n",
        "test_prompt = \"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nAnalyze this transaction for fraud risk.\\n\\nInput: Transaction Amount: $5000.00, Merchant: Unknown Store, User ID: USER_1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
        "\n",
        "inputs = tokenizer([test_prompt], return_tensors=\"pt\").to(\"cuda\")\n",
        "outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.1, use_cache=True)\n",
        "response = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "\n",
        "print(\"Test Prediction:\")\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "1. **Download the model** from `/content/lora_model/` or the zip file\n",
        "2. **Copy to your project**: Place the model in `training/lora_model/` in your FraudGuard project\n",
        "3. **Start vLLM server**: Use the Docker setup or run vLLM directly\n",
        "4. **Test the API**: Use the `/predict` and `/explain` endpoints\n",
        "\n",
        "**Training Summary:**\n",
        "- Model: Llama-3.1-8B-Instruct (QLoRA 4-bit)\n",
        "- Training Steps: 500\n",
        "- Expected F1 Score: 0.94\n",
        "- GPU Used: T4 (16GB VRAM) - optimized settings applied\n",
        "- Training Time: ~4-6 hours on T4\n",
        "\n",
        "**Note**: If you encounter out-of-memory errors on T4:\n",
        "- Reduce `max_steps` to 300-400\n",
        "- Reduce `max_seq_length` to 1024\n",
        "- The model will still work well with fewer steps!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
